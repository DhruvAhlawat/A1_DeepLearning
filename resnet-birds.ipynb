{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8002003,"sourceType":"datasetVersion","datasetId":4712300}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image\nimport glob\nimport time\nimport os\nimport torchmetrics\nimport matplotlib.pyplot as plt\nimport pickle\nfrom torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\nfrom torchvision.datasets import ImageFolder\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:01.758015Z","iopub.execute_input":"2024-04-02T06:09:01.758606Z","iopub.status.idle":"2024-04-02T06:09:10.403258Z","shell.execute_reply.started":"2024-04-02T06:09:01.758576Z","shell.execute_reply":"2024-04-02T06:09:10.402464Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# part A : Batch Normalisation\nclass BatchNorm2d(nn.Module): #My definition of Batch Normalisation.\n    def __init__(self, size):\n        super(BatchNorm2d, self).__init__()\n        self.epsilon = 1e-5;\n        shape = (1, size, 1, 1)\n        self.gamma = nn.Parameter(torch.ones(shape)) # the scaling factor that determines the new standard deviation.\n        self.beta = nn.Parameter(torch.zeros(shape)) # the bias that is the new mean.\n        self.running_sum = torch.zeros(shape).to(device);\n        self.running_square_sum = torch.zeros(shape).to(device);\n        self.total = 0;\n    def forward(self, X):\n        #if we are in training mode, then we use the mean and variance of this batch.\n        if self.training:\n            mean = torch.mean(X, dim = (0,2,3), keepdim = True);\n            var = torch.var(X,dim = (0,2,3), keepdim = True);\n            self.total += 1;\n            self.running_sum += mean;\n            self.running_square_sum += var;\n        else:\n            mean = self.running_sum / self.total;\n            var = self.running_square_sum / self.total;\n        # X_mean = torch.ones(X.shape) * mean;\n#         X_mean = mean.expand_as(X);\n        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon); #epsilon is added for non-zero denominator\n        # X_transformed = self.gamma * X_transformed + self.beta;\n        X_transformed = X_transformed * self.gamma + self.beta;\n        return X_transformed;\n# part B : Instance Normalisation.\nclass InstanceNormalisation2d(nn.Module):\n    def __init__(self, size):\n        super(InstanceNormalisation2d, self).__init__();\n        self.epsilon = 1e-5;\n        self.gamma = nn.Parameter(torch.ones((1, size, 1, 1)));\n        self.beta = nn.Parameter(torch.zeros((1, size, 1, 1)));\n    def forward(self, X):\n        mean = torch.mean(X, dim = (2,3), keepdim = True);\n        var = torch.var(X, dim = (2,3), keepdim = True);\n        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n        X_transformed = X_transformed * self.gamma + self.beta;\n        return X_transformed;\nclass BatchInstanceNormalisation2d(nn.Module):\n    def __init__(self, size):\n        super(BatchInstanceNormalisation2d, self).__init__();\n        self.batch_norm = BatchNorm2d(size);\n        self.instance_norm = InstanceNormalisation2d(size);\n        shape = (1, size, 1, 1)\n        self.rho = nn.Parameter(torch.ones(shape));\n        self.epsilon = 1e-5;\n        self.gamma = nn.Parameter(torch.ones(shape)) # the scaling factor that determines the new standard deviation.\n        self.beta = nn.Parameter(torch.zeros(shape)) # the bias that is the new mean.\n    def forward(self, X):\n        #if we are in training mode, then we use the mean and variance of this batch.\n        X_batch = self.batch_norm(X);\n        X_instance = self.instance_norm(X);\n        #X_batch = (X - mean) / torch.sqrt(var + self.epsilon); #epsilon is added for non-zero denominator\n        #instance_mean = torch.mean(X, dim = (2,3), keepdim = True);\n        #instance_var = torch.var(X, dim = (2,3), keepdim = True);\n        #X_instance = (X - instance_mean) / torch.sqrt(instance_var + self.epsilon); #this is the instance value.\n        X_transformed = self.rho * X_batch + (1 - self.rho) * X_instance;\n        X_transformed = X_transformed * self.gamma + self.beta;\n        return X_transformed;\n    \nclass LayerNormalisation2d(nn.Module):\n    def __init__(self, size = None):\n        super(LayerNormalisation2d, self).__init__();\n        self.epsilon = 1e-5; #it actually has no use for size, since it normalizes accross the channels as well.\n        self.gamma = nn.Parameter(torch.ones((1, 1, 1, 1)));\n        self.beta = nn.Parameter(torch.zeros((1, 1, 1, 1)));\n    def forward(self, X):\n        mean = torch.mean(X, dim = (1,2,3), keepdim = True); #normalizes accross the channel dimension as well.\n        var = torch.var(X, dim = (1,2,3), keepdim = True);\n        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n        X_transformed = X_transformed * self.gamma + self.beta;\n        return X_transformed;\n\nclass GroupNormalisation2d(nn.Module):\n    def __init__(self, size, groups = 8):\n        super(GroupNormalisation2d, self).__init__();\n        self.epsilon = 1e-5;\n        self.gamma = nn.Parameter(torch.ones((1, size, 1, 1)));\n        self.beta = nn.Parameter(torch.zeros((1, size, 1, 1)));\n        self.groups = groups;\n    def forward(self, X):\n        shape = X.shape;\n        X = X.view(shape[0], self.groups, shape[1]//self.groups, shape[2], shape[3]);\n        mean = torch.mean(X, dim = (2,3,4), keepdim = True);\n        var = torch.var(X, dim = (2,3,4), keepdim = True);\n        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n        X_transformed = X_transformed.view(shape);\n        X_transformed = X_transformed * self.gamma + self.beta;\n        return X_transformed;","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:27.261964Z","iopub.execute_input":"2024-04-02T06:10:27.262715Z","iopub.status.idle":"2024-04-02T06:10:27.291641Z","shell.execute_reply.started":"2024-04-02T06:10:27.262677Z","shell.execute_reply":"2024-04-02T06:10:27.290689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Describing the ResNet class","metadata":{}},{"cell_type":"code","source":"class ResNetBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride = 1, norm = nn.BatchNorm2d):\n        super(ResNetBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1,bias=False)\n        self.bn1 = norm(out_channels).to(device=device)\n        self.relu = nn.ReLU()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1,bias=False)\n        self.bn2 = norm(out_channels).to(device=device)\n        self.stride = stride;\n        self.conv1x1 = None; self.bn1x1 = None; #Originally.\n        if(self.stride != 1):\n            self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, padding = 0,bias=False)\n            self.bn1x1 = nn.BatchNorm2d(out_channels,device=device);\n\n    def forward(self, x):\n#         residual = x;\n        o = self.conv1(x)\n        o = self.bn1(o);\n        o = F.relu(o).to(device); #The first layer for the resnet block.\n        o = self.conv2(o); \n        o = self.bn2(o); \n        if(self.stride != 1): #this means we have to perform 1x1 convolutions\n            x = self.conv1x1(x); \n            x = self.bn1x1(x); #Applying the 1x1 convolutions to maintain the size.\n        o += x; #inplace addition.\n        o = F.relu(o); #the second layer output completed here.\n        return o;\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:10.405451Z","iopub.execute_input":"2024-04-02T06:09:10.405931Z","iopub.status.idle":"2024-04-02T06:09:10.416164Z","shell.execute_reply.started":"2024-04-02T06:09:10.405898Z","shell.execute_reply":"2024-04-02T06:09:10.415314Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, in_channels, num_classes, n, norm=nn.BatchNorm2d):\n        super(ResNet, self).__init__();\n        self.n = n;\n        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1, device=device,bias=False);\n        self.bn1 = norm(16).to(device=device); #of output size.\n        self.relu = nn.ReLU();\n        self.res16 = nn.ModuleList();\n        for i in range(n):\n            self.res16.append(ResNetBlock(16,16, norm=norm).to(device));\n        self.res32 = nn.ModuleList();\n        self.res32.append(ResNetBlock(16,32,2, norm=norm).to(device)); #1 Block which will change the size of the input.\n        for i in range(n-1):\n            self.res32.append(ResNetBlock(32,32,norm=norm).to(device));\n        self.res64 = nn.ModuleList();\n        self.res64.append(ResNetBlock(32,64,2,norm=norm).to(device));\n        for i in range(n-1):\n            self.res64.append(ResNetBlock(64,64,norm=norm).to(device));\n        \n        self.final_mean_pool = nn.AdaptiveAvgPool2d(output_size=(1,1));\n        self.fc = nn.Linear(64, num_classes);\n\n    def forward(self, o):\n        o = self.conv1(o)\n        o = self.bn1(o)\n        o = self.relu(o)\n        for i in range(len(self.res16)):\n            o = self.res16[i](o)\n        for i in range(len(self.res32)):\n            o = self.res32[i](o);\n        for i in range(len(self.res64)):\n            o = self.res64[i](o);\n        o = self.final_mean_pool(o); \n        o = o.view(o.size(0), -1);\n#         o = torch.flatten(o, start_dim=1); #Flattening from after the batch index.\n        o = self.fc(o); #final layer.\n        return o;\n        ","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-04-02T06:09:10.417268Z","iopub.execute_input":"2024-04-02T06:09:10.417643Z","iopub.status.idle":"2024-04-02T06:09:10.440838Z","shell.execute_reply.started":"2024-04-02T06:09:10.417612Z","shell.execute_reply":"2024-04-02T06:09:10.440150Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class bird_dataset(Dataset):\n    def __init__(self, datapath): #Either test, train, or val datafolder.\n        self.datapath = datapath;\n        folder_list = glob.glob(datapath + \"/*\");\n        self.data = [];\n        self.labels = set();\n        for folder in folder_list:\n            label = os.path.basename(folder); #gets the last name of the folder, which is the label.\n            self.labels.add(label);\n            file_list = glob.glob(folder + \"/*\");\n            for file in file_list:\n                self.data.append((file, label));\n        self.labels = list(self.labels);\n        self.label_to_index = {label: i for i, label in enumerate(self.labels)};\n    \n    def __len__(self):\n        return len(self.data);\n    \n    def __getitem__(self, idx):\n        img_path, label = self.data[idx];\n        img = read_image(img_path)\n        img = img/255;\n        # print(img);\n        # img = transforms.ToTensor()(img); #converts the image to a tensor, but read_image already does this.\n        label = self.label_to_index[label]; #using labels as indices for the classes, instead of names.\n        # label_arr = np.zeros(len(self.labels));\n        # label_arr[label] = 1;\n        return img, label;\n\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-04-02T06:09:10.441751Z","iopub.execute_input":"2024-04-02T06:09:10.442030Z","iopub.status.idle":"2024-04-02T06:09:10.454242Z","shell.execute_reply.started":"2024-04-02T06:09:10.442007Z","shell.execute_reply":"2024-04-02T06:09:10.453499Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### creating the dataloaders","metadata":{}},{"cell_type":"code","source":"## Parameters for the network.32\nnum_classes = 25; \nn = 2; #6n + 2 layers.\nin_channels = 3; #RGB images.\nbatch_size = 32; #Probably wont run on my laptop with just 4GB of VRAM.\ninitial_learning_rate = 0.01;\nnum_epochs = 50; ","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:10.455954Z","iopub.execute_input":"2024-04-02T06:09:10.456257Z","iopub.status.idle":"2024-04-02T06:09:10.466084Z","shell.execute_reply.started":"2024-04-02T06:09:10.456228Z","shell.execute_reply":"2024-04-02T06:09:10.465237Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageFolder(root=\"/kaggle/input/birds-25/Birds_25/train\",transform=transforms.ToTensor())\ntest_dataset = ImageFolder(root=\"/kaggle/input/birds-25/Birds_25/test\",transform=transforms.ToTensor())\nval_dataset = ImageFolder(root=\"/kaggle/input/birds-25/Birds_25/val\",transform=transforms.ToTensor())\n# Train_loader = DataLoader(bird_dataset(\"Birds_25/train\"), batch_size=batch_size, shuffle=True); #This is how to use the DataLoader to get batches of data.\nTrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 4);\nTest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers = 2);\nVal_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers = 2);\n\n# Test_loader = DataLoader(bird_dataset(\"/kaggle/input/birds-2/Birds_25/test\"), batch_size=batch_size, shuffle=True);\n# Val_loader = DataLoader(bird_dataset(\"/kaggle/input/birds-2/Birds_25/val\"), batch_size=batch_size, shuffle=True);","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:10.467258Z","iopub.execute_input":"2024-04-02T06:09:10.467845Z","iopub.status.idle":"2024-04-02T06:09:33.281620Z","shell.execute_reply.started":"2024-04-02T06:09:10.467817Z","shell.execute_reply":"2024-04-02T06:09:33.280781Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# model = ResNet(in_channels, num_classes, n, norm=BatchNorm2d).to(device);\n\nmodel = ResNet(in_channels, num_classes, n, norm=BatchInstanceNormalisation2d).to(device);\nprint( \"DOING MY IMPLEMENTATION OF Batch-Instance NORMALISATION.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:30.231585Z","iopub.execute_input":"2024-04-02T06:10:30.232489Z","iopub.status.idle":"2024-04-02T06:10:30.283115Z","shell.execute_reply.started":"2024-04-02T06:10:30.232454Z","shell.execute_reply":"2024-04-02T06:10:30.282120Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"DOING MY IMPLEMENTATION OF Batch-Instance NORMALISATION.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr= initial_learning_rate);\n# optimizer = optim.SGD(model.parameters(), lr = initial_learning_rate, momentum = 0.92);","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:33.726336Z","iopub.execute_input":"2024-04-02T06:10:33.726673Z","iopub.status.idle":"2024-04-02T06:10:33.732626Z","shell.execute_reply.started":"2024-04-02T06:10:33.726647Z","shell.execute_reply":"2024-04-02T06:10:33.731510Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(model, optimizer, filename):\n    checkpoint = torch.load(filename);\n    model.load_state_dict(checkpoint['model_state_dict']);\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict']);\n    epoch = checkpoint['epoch'];\n    loss = checkpoint['loss'];\n    return model, optimizer, epoch, loss;\n\ndef store_checkpoint(model, optimizer, epoch, loss, filename):\n    torch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'epoch': epoch,\n            'loss': loss,\n            }, filename);","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:34.018472Z","iopub.execute_input":"2024-04-02T06:10:34.018907Z","iopub.status.idle":"2024-04-02T06:10:34.025267Z","shell.execute_reply.started":"2024-04-02T06:10:34.018869Z","shell.execute_reply":"2024-04-02T06:10:34.024283Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Check accuracy on training and test to see how good our model is.\nmacroF1 = MulticlassF1Score(num_classes=num_classes, average='macro')\nmicroF1 = MulticlassF1Score(num_classes=num_classes, average='micro')\naccuracy = MulticlassAccuracy(num_classes=num_classes)\ndef check_eval(loader, model):\n    correct = 0; num_samples = 0;\n    model.eval(); #Sets it into evaluation mode, so no dropout or batchnorm\n    preds = []; labels = [];\n    with torch.no_grad():\n        for x,y in loader:\n            x = x.to(device);\n            y = y.to(device);\n            #x = x.reshape(x.shape[0], -1);\n            scores = model(x);\n            _, predictions = scores.max(1);\n            preds.extend(predictions);\n            labels.extend(y);\n    \n    preds = torch.tensor(preds); labels = torch.tensor(labels);\n    acc = accuracy(preds, labels); macF1 = macroF1(preds, labels); micF1 = microF1(preds, labels);\n    model.train();\n    return (acc, macF1, micF1);","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:34.426204Z","iopub.execute_input":"2024-04-02T06:10:34.426925Z","iopub.status.idle":"2024-04-02T06:10:34.442022Z","shell.execute_reply.started":"2024-04-02T06:10:34.426889Z","shell.execute_reply":"2024-04-02T06:10:34.441154Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# print(check_eval(Train_loader, model));\n# print(check_eval(Val_loader, model));\n# print(check_eval(Test_loader, model));","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:34.834395Z","iopub.execute_input":"2024-04-02T06:10:34.835178Z","iopub.status.idle":"2024-04-02T06:10:34.838865Z","shell.execute_reply.started":"2024-04-02T06:10:34.835145Z","shell.execute_reply":"2024-04-02T06:10:34.837922Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\ndef train_model(model, traindata):\n    for epoch in range(num_epochs):\n        start = time.time();\n        mean_loss = 0; total_batches = 0;\n        print(\"epoch: \", epoch+1);\n        epochlabels = []; epochoutputs = [];\n        for i, (images, labels) in enumerate(Train_loader):\n            total_batches += 1;\n            images = images.to(device);\n            labels = labels.to(device);\n            #Forward pass\n            outputs = model(images);\n            loss = criterion(outputs, labels);\n            #Backward pass\n            optimizer.zero_grad(); #Zeroes the gradients before backpropagation.\n            loss.backward(); #Backpropagation.\n            optimizer.step(); #Updates the weights.\n            mean_loss += loss.item();\n            _, preds = outputs.max(1);\n            epochlabels.extend(labels);\n            epochoutputs.extend(preds); #stores the values predicted each epoch.\n            print(\"batch: \", i+1, \"loss: \", mean_loss/total_batches, end = \"          \\r\");\n        epoch_time = time.time() - start;\n        for g in optimizer.param_groups:\n            g['lr'] = g['lr']/1.06; #Decay the learning rate by a constant after each epoch.\n        store_checkpoint(model, optimizer, epoch, loss.item(), \"checkpoint_epoch\" + str(epoch) + \".pth\");\n        epochlabels = torch.tensor(epochlabels);\n        epochoutputs = torch.tensor(epochoutputs);\n        mic = microF1(epochoutputs, epochlabels); mac = macroF1(epochoutputs, epochlabels); acc = accuracy(epochoutputs, epochlabels);\n        traindata['train'].append((acc, mac, mic));\n        valacc, valmac, valmic = check_eval(Val_loader, model);\n        traindata['val'].append((valacc, valmac, valmic));\n        testacc, testmac, testmic = check_eval(Test_loader, model);\n        traindata['test'].append((testacc, testmac, testmic));\n        end = time.time();\n        print(epoch+1, \"th epoch: \", epoch_time, \"s, total:\", end - start ,\"mean loss: \", mean_loss/total_batches, \"          \");\n        print(\"VAL acc, mac, mic :\", (valacc, valmac, valmic))\n        for name, param in model.named_parameters():\n            if name.split('.')[-1] == 'rho':\n                setattr(model, name, torch.clamp(param, 0, 1)) #clamping it for Batch Instance normalization\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:35.178417Z","iopub.execute_input":"2024-04-02T06:10:35.178802Z","iopub.status.idle":"2024-04-02T06:10:35.192811Z","shell.execute_reply.started":"2024-04-02T06:10:35.178771Z","shell.execute_reply":"2024-04-02T06:10:35.191806Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindata = {};\ntraindata['val'] = [];\ntraindata['train'] = [];\ntraindata['test'] = [];\ntrain_start = time.time();\ntrain_model(model, traindata);\nduration = time.time() - train_start;\nprint(\"\\n\\n---------Training finished after \", duration, \" seconds--------\\n\\n\");","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:10:36.586733Z","iopub.execute_input":"2024-04-02T06:10:36.587125Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch:  1\nbatch:  280 loss:  2.7381926689829146          \r","output_type":"stream"}]},{"cell_type":"code","source":"# with open(\"/kaggle/input/checkpoints-part1a/traindata.pickle\", \"rb\") as file:\n#     traindata = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:33.672092Z","iopub.status.idle":"2024-04-02T06:09:33.672457Z","shell.execute_reply.started":"2024-04-02T06:09:33.672297Z","shell.execute_reply":"2024-04-02T06:09:33.672311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('traindata.pickle', 'wb') as file:\n    pickle.dump(traindata, file);\nstore_checkpoint(model, optimizer, 51, 2, \"final_chkpnt.pth\"); #stores the model.","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:33.673412Z","iopub.status.idle":"2024-04-02T06:09:33.673701Z","shell.execute_reply.started":"2024-04-02T06:09:33.673554Z","shell.execute_reply":"2024-04-02T06:09:33.673566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"VAL: \", check_eval(Val_loader, model));\nprint(\"TEST: \", check_eval(Test_loader, model));\nprint(\"TRAIN: \", check_eval(Train_loader, model));","metadata":{"execution":{"iopub.status.busy":"2024-04-02T06:09:33.674852Z","iopub.status.idle":"2024-04-02T06:09:33.675228Z","shell.execute_reply.started":"2024-04-02T06:09:33.675005Z","shell.execute_reply":"2024-04-02T06:09:33.675050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# traindata['val'] = [];\n# for i in range(50):\n#     print(i, \" doing     \\r\")\n#     file_name = '/kaggle/input/checkpoints-part1a/checkpoint_epoch' + str(i) + '.pth'\n#     load_checkpoint(model, optimizer, file_name)\n#     valacc, valmac, valmic = check_eval(Val_loader, model);\n#     traindata['val'].append((valacc, valmac, valmic));\n","metadata":{"execution":{"iopub.status.busy":"2024-04-01T23:19:12.772957Z","iopub.status.idle":"2024-04-01T23:19:12.773310Z","shell.execute_reply.started":"2024-04-01T23:19:12.773150Z","shell.execute_reply":"2024-04-01T23:19:12.773165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_epoch(data, name):\n    index = list(range(1, len(data) + 1))\n    accuracy, micro_f1, macro_f1 = zip(*data)\n\n    # Plotting\n    fig, ax = plt.subplots(figsize=(10, 8))\n\n    ax.plot(index, accuracy, marker='o', label='Accuracy')\n    ax.plot(index, micro_f1, marker='s', label='Micro F1')\n    ax.plot(index, macro_f1, marker='^', label='Macro F1')\n\n    ax.set_title('Performance Metrics for ' + name)\n    ax.set_xlabel('List Index')\n    ax.set_ylabel('Score')\n    ax.set_xticks(index)\n    ax.legend()\n    ax.grid(True)\n\n    plt.tight_layout()\n    plt.savefig(name) #The fig should be saved before doing plt.show().\n    plt.show()\nplot_epoch(traindata['train'], 'train plot');\nplot_epoch(traindata['val'], 'val plot');\nplot_epoch(traindata['test'], 'test plot');","metadata":{"execution":{"iopub.status.busy":"2024-04-01T23:19:12.774529Z","iopub.status.idle":"2024-04-01T23:19:12.774844Z","shell.execute_reply.started":"2024-04-01T23:19:12.774685Z","shell.execute_reply":"2024-04-01T23:19:12.774697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}