{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","from torchvision.io import read_image\n","import glob\n","import time\n","import os\n","import torchmetrics\n","import matplotlib.pyplot as plt\n","import pickle\n","from torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\n","from torchvision.datasets import ImageFolder\n","import argparse\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# part A : Batch Normalisation\n","class BatchNorm2d(nn.Module): #My definition of Batch Normalisation.\n","    def __init__(self, size):\n","        super(BatchNorm2d, self).__init__()\n","        self.epsilon = 1e-5;\n","        shape = (1, size, 1, 1)\n","        self.gamma = nn.Parameter(torch.ones(shape)) # the scaling factor that determines the new standard deviation.\n","        self.beta = nn.Parameter(torch.zeros(shape)) # the bias that is the new mean.\n","        self.running_sum = torch.zeros(shape).to(device);\n","        self.running_square_sum = torch.zeros(shape).to(device);\n","        self.total = 0;\n","    def forward(self, X):\n","        #if we are in training mode, then we use the mean and variance of this batch.\n","        if self.training:\n","            mean = torch.mean(X, dim = (0,2,3), keepdim = True);\n","            var = torch.var(X,dim = (0,2,3), keepdim = True);\n","            self.total += 1;\n","            self.running_sum += mean;\n","            self.running_square_sum += var;\n","        else:\n","            mean = self.running_sum / self.total;\n","            var = self.running_square_sum / self.total;\n","        # X_mean = torch.ones(X.shape) * mean;\n","#         X_mean = mean.expand_as(X);\n","        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon); #epsilon is added for non-zero denominator\n","        # X_transformed = self.gamma * X_transformed + self.beta;\n","        X_transformed = X_transformed * self.gamma + self.beta;\n","        return X_transformed;\n","class InstanceNormalisation2d(nn.Module):\n","    def __init__(self, size):\n","        super(InstanceNormalisation2d, self).__init__();\n","        self.epsilon = 1e-5;\n","        self.gamma = nn.Parameter(torch.ones((1, size, 1, 1)));\n","        self.beta = nn.Parameter(torch.zeros((1, size, 1, 1)));\n","    def forward(self, X):\n","        mean = torch.mean(X, dim = (2,3), keepdim = True);\n","        var = torch.var(X, dim = (2,3), keepdim = True);\n","        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n","        X_transformed = X_transformed * self.gamma + self.beta;\n","        return X_transformed;\n","class BatchInstanceNormalisation2d(nn.Module):\n","    def __init__(self, size):\n","        super(BatchInstanceNormalisation2d, self).__init__();\n","        self.batch_norm = BatchNorm2d(size);\n","        self.instance_norm = InstanceNormalisation2d(size);\n","        shape = (1, size, 1, 1)\n","        self.rho = nn.Parameter(torch.ones(shape));\n","        self.epsilon = 1e-5;\n","        self.gamma = nn.Parameter(torch.ones(shape)) # the scaling factor that determines the new standard deviation.\n","        self.beta = nn.Parameter(torch.zeros(shape)) # the bias that is the new mean.\n","    def forward(self, X):\n","        #if we are in training mode, then we use the mean and variance of this batch.\n","        X_batch = self.batch_norm(X);\n","        X_instance = self.instance_norm(X);\n","        #X_batch = (X - mean) / torch.sqrt(var + self.epsilon); #epsilon is added for non-zero denominator\n","        #instance_mean = torch.mean(X, dim = (2,3), keepdim = True);\n","        #instance_var = torch.var(X, dim = (2,3), keepdim = True);\n","        #X_instance = (X - instance_mean) / torch.sqrt(instance_var + self.epsilon); #this is the instance value.\n","        X_transformed = self.rho * X_batch + (1 - self.rho) * X_instance;\n","        X_transformed = X_transformed * self.gamma + self.beta;\n","        return X_transformed;\n","class LayerNormalisation2d(nn.Module):\n","    def __init__(self, size = None):\n","        super(LayerNormalisation2d, self).__init__();\n","        self.epsilon = 1e-5; #it actually has no use for size, since it normalizes accross the channels as well.\n","        self.gamma = nn.Parameter(torch.ones((1, 1, 1, 1)));\n","        self.beta = nn.Parameter(torch.zeros((1, 1, 1, 1)));\n","    def forward(self, X):\n","        mean = torch.mean(X, dim = (1,2,3), keepdim = True); #normalizes accross the channel dimension as well.\n","        var = torch.var(X, dim = (1,2,3), keepdim = True);\n","        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n","        X_transformed = X_transformed * self.gamma + self.beta;\n","        return X_transformed;\n","class GroupNormalisation2d(nn.Module):\n","    def __init__(self, size, groups = 8):\n","        super(GroupNormalisation2d, self).__init__();\n","        self.epsilon = 1e-5;\n","        self.gamma = nn.Parameter(torch.ones((1, size, 1, 1)));\n","        self.beta = nn.Parameter(torch.zeros((1, size, 1, 1)));\n","        self.groups = groups;\n","    def forward(self, X):\n","        shape = X.shape;\n","        X = X.view(shape[0], self.groups, shape[1]//self.groups, shape[2], shape[3]);\n","        mean = torch.mean(X, dim = (2,3,4), keepdim = True);\n","        var = torch.var(X, dim = (2,3,4), keepdim = True);\n","        X_transformed = (X - mean) / torch.sqrt(var + self.epsilon);\n","        X_transformed = X_transformed.view(shape);\n","        X_transformed = X_transformed * self.gamma + self.beta;\n","        return X_transformed;\n","class NoNormalisation(nn.Module):\n","    def __init__(self, size):\n","        super(NoNormalisation, self).__init__();\n","    def forward(self, X):\n","        return X; #no transformations applied."]},{"cell_type":"markdown","metadata":{},"source":["### Describing the ResNet class"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["class ResNetBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride = 1, norm = nn.BatchNorm2d):\n","        super(ResNetBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1,bias=False)\n","        self.bn1 = norm(out_channels).to(device=device)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1,bias=False)\n","        self.bn2 = norm(out_channels).to(device=device)\n","        self.stride = stride;\n","        self.conv1x1 = None; self.bn1x1 = None; #Originally.\n","        if(self.stride != 1):\n","            self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, padding = 0,bias=False)\n","            self.bn1x1 = nn.BatchNorm2d(out_channels,device=device);\n","\n","    def forward(self, x):\n","#         residual = x;\n","        o = self.conv1(x)\n","        o = self.bn1(o);\n","        o = F.relu(o).to(device); #The first layer for the resnet block.\n","        o = self.conv2(o); \n","        o = self.bn2(o); \n","        if(self.stride != 1): #this means we have to perform 1x1 convolutions\n","            x = self.conv1x1(x); \n","            x = self.bn1x1(x); #Applying the 1x1 convolutions to maintain the size.\n","        o += x; #inplace addition.\n","        o = F.relu(o); #the second layer output completed here.\n","        return o;\n","class ResNet(nn.Module):\n","    def __init__(self, in_channels, num_classes, n, norm=nn.BatchNorm2d):\n","        super(ResNet, self).__init__();\n","        self.n = n;\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1, device=device,bias=False);\n","        self.bn1 = norm(16).to(device=device); #of output size.\n","        self.relu = nn.ReLU();\n","        self.res16 = nn.ModuleList();\n","        for i in range(n):\n","            self.res16.append(ResNetBlock(16,16, norm=norm).to(device));\n","        self.res32 = nn.ModuleList();\n","        self.res32.append(ResNetBlock(16,32,2, norm=norm).to(device)); #1 Block which will change the size of the input.\n","        for i in range(n-1):\n","            self.res32.append(ResNetBlock(32,32,norm=norm).to(device));\n","        self.res64 = nn.ModuleList();\n","        self.res64.append(ResNetBlock(32,64,2,norm=norm).to(device));\n","        for i in range(n-1):\n","            self.res64.append(ResNetBlock(64,64,norm=norm).to(device));\n","        \n","        self.final_mean_pool = nn.AdaptiveAvgPool2d(output_size=(1,1));\n","        self.fc = nn.Linear(64, num_classes);\n","\n","    def forward(self, o):\n","        o = self.conv1(o)\n","        o = self.bn1(o)\n","        o = self.relu(o)\n","        for i in range(len(self.res16)):\n","            o = self.res16[i](o)\n","        for i in range(len(self.res32)):\n","            o = self.res32[i](o);\n","        for i in range(len(self.res64)):\n","            o = self.res64[i](o);\n","        o = self.final_mean_pool(o); \n","        o = o.view(o.size(0), -1);\n","#         o = torch.flatten(o, start_dim=1); #Flattening from after the batch index.\n","        o = self.fc(o); #final layer.\n","        return o;"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### creating the dataloaders"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["## Parameters for the network.32\n","num_classes = 25; \n","n = 2; #6n + 2 layers.\n","in_channels = 3; #RGB images.\n","batch_size = 32; #Probably wont run on my laptop with just 4GB of VRAM."]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["\n","def load_checkpoint(model, optimizer, filename):\n","    checkpoint = torch.load(filename);\n","    model.load_state_dict(checkpoint['model_state_dict']);\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict']);\n","    epoch = checkpoint['epoch'];\n","    loss = checkpoint['loss'];\n","    return model, optimizer, epoch, loss;\n","def store_checkpoint(model, optimizer, epoch, loss, filename):\n","    torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'epoch': epoch,\n","            'loss': loss,\n","            }, filename);"]},{"cell_type":"markdown","metadata":{},"source":["python3 infer.py -model_file <path to the trained model> --normalization [ bn | in | bin | ln | gn | nn | inbuilt ] --n [ 1 |  2 | 3  ] --test_data_file <path to the directory containing the images> --output_file <file containing the prediction in the same order as the images in directory>\n","\n","Example: \n","\n","python3 infer.py --model_file models/part_1.2_bn.pth --normalization bn --n 3 --test_data_file birds_test --output_file output.txt\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["# model = ResNet(in_channels, num_classes, n, norm=BatchNorm2d).to(device);\n","#model = ResNet(in_channels, num_classes, n).to(device);\n","#print(\"Doing Inbuilt implementation with batch size 32\");\n","# here we get the data from argparse, about what we want.\n","parser = argparse.ArgumentParser(description='ResNet implementation with different normalizations');\n","parser.add_argument('--normalization', type=str, default='inbuilt', help='normalization type for the network');\n","parser.add_argument('--n', type=int, default=2, help='n value for the network');\n","parser.add_argument('--test_data_file', type=str, default='', help='test data file');\n","parser.add_argument('--output_file', type=str, default='output.txt', help='output file');\n","parser.add_argument('--model_file', type=str, default='models/part_1.2_gn.pth', help='output file');\n","#how to use these args?"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["args = parser.parse_args(\"--model_file models/part_1.2_gn.pth --normalization gn --n 2 --test_data_file birds_test/birds_test --output_file output.txt\".split());\n","# args = parser.parse_args();\n","norm = nn.BatchNorm2d; #by Default.\n","if(args.normalization == 'bn'):\n","    norm = BatchNorm2d;\n","elif(args.normalization == 'in'):\n","    norm = InstanceNormalisation2d;\n","elif(args.normalization == 'bin'):\n","    norm = BatchInstanceNormalisation2d;\n","elif(args.normalization == 'ln'):\n","    norm = LayerNormalisation2d;\n","elif(args.normalization == 'gn'):\n","    norm = GroupNormalisation2d;\n","elif(args.normalization == 'nn'):\n","    norm = NoNormalisation;"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["[('normalization', 'gn'),\n"," ('n', 2),\n"," ('test_data_file', 'birds_test'),\n"," ('output_file', 'output.txt'),\n"," ('model_file', 'models/part_1.2_gn.pth')]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["args._get_kwargs()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DOING MY IMPLEMENTATION OF gn with batch_size 32\n"]}],"source":["model = ResNet(in_channels, num_classes, args.n, norm=norm).to(device); #n should be equal to 2 hopefully.\n","optimizer = optim.Adam(model.parameters(), lr=0.001); #Adam optimizer, although it is not needed but load checkpoint uses it.\n","load_checkpoint(model, optimizer, args.model_file)\n","print( \"DOING MY IMPLEMENTATION OF {} with batch_size\".format(args.normalization), batch_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["#Check accuracy on training and test to see how good our model is."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n","# from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n","# from pytorch_grad_cam.utils.image import show_cam_on_image"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["class bird_dataset(Dataset):\n","    def __init__(self, datapath, train = True): #Either test, train, or val datafolder.\n","        self.datapath = datapath;\n","        self.train = train;\n","        if(train):\n","            folder_list = glob.glob(datapath + \"/*\");\n","            self.data = [];\n","            self.labels = set();\n","            for folder in folder_list:\n","                label = os.path.basename(folder); #gets the last name of the folder, which is the label.\n","                self.labels.add(label);\n","                file_list = glob.glob(folder + \"/*\");\n","                for file in file_list:\n","                    self.data.append((file, label));\n","            self.labels = list(self.labels);\n","            self.label_to_index = {label: i for i, label in enumerate(self.labels)};\n","        else:\n","            file_list = glob.glob(datapath + \"/*\");\n","            self.data = [];\n","            label = 'dunno';\n","            for file in file_list:\n","                self.data.append((file, label));\n","            self.labels = [label];\n","            self.label_to_index = {label: i for i, label in enumerate(self.labels)};\n","            #converts the label to an index.\n","    def __len__(self):\n","        return len(self.data);\n","    \n","    def __getitem__(self, idx):\n","        img_path, label = self.data[idx];\n","        img = Image.open(img_path)\n","        img = np.array(img)/255; #normalizing the image, maybe not necessary but just to confirm.\n","        img = transforms.ToTensor()(img);\n","        label = self.label_to_index[label]; #using labels as indices for the classes, instead of names.\n","        #this label doesn't really correspond to anything in the dataset.\n","        # label_arr = np.zeros(len(self.labels));\n","        # label_arr[label] = 1;\n","        path = os.path.basename(img_path);\n","        return img, path;"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 4;\n","Test_loader = DataLoader(bird_dataset(args.test_data_file, train=False), batch_size=batch_size, shuffle=False); #lower batch size during testing."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["class_to_idx = {'Asian-Green-Bee-Eater': 0, 'Brown-Headed-Barbet': 1, 'Cattle-Egret': 2, 'Common-Kingfisher': 3, 'Common-Myna': 4, 'Common-Rosefinch': 5, 'Common-Tailorbird': 6, 'Coppersmith-Barbet': 7, 'Forest-Wagtail': 8, 'Gray-Wagtail': 9, 'Hoopoe': 10, 'House-Crow': 11, 'Indian-Grey-Hornbill': 12, 'Indian-Peacock': 13, 'Indian-Pitta': 14, 'Indian-Roller': 15, 'Jungle-Babbler': 16, 'Northern-Lapwing': 17, 'Red-Wattled-Lapwing': 18, 'Ruddy-Shelduck': 19, 'Rufous-Treepie': 20, 'Sarus-Crane': 21, 'White-Breasted-Kingfisher': 22, 'White-Breasted-Waterhen': 23, 'White-Wagtail': 24}\n","idx_to_class = {v: k for k, v in class_to_idx.items()}"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["outputs = {}; #outputs dictionary, for each line.\n","total_done = 0;\n","for x,y in Test_loader:\n","    indices = [i[:-4] for i in y];\n","    x = x.to(device, dtype = torch.float32);\n","    model_outputs = model(x);\n","    _, preds = model_outputs.max(1);\n","    for i in range(len(preds)):\n","        outputs[indices[i]] = preds[i];\n","    total_done += len(preds);\n","    if(total_done %(batch_size * 10) == 0):\n","        print(\"total done: \", total_done, end = \"         \\r\");"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["beginning to write our predictions to output.txt\n"]}],"source":["#finally write the outputs to the file.\n","#first we make it a list of tuples and then order it by the indices\n","#then we write it to the file.\n","preds = [(key, outputs[key]) for key in outputs.keys()];\n","try:\n","    preds = sorted(preds, key = lambda x: int(x[0])); # Sort by the indices.\n","except Exception as e:\n","    print(\"couldnt sort by indices, maybe an error?\", e);\n","\n","print(\"beginning to write our predictions to {}\".format(args.output_file));\n","with open(args.output_file, 'w') as f:\n","    for i in range(len(preds)):\n","        f.write(idx_to_class[preds[i][1].item()] + \"\\n\");"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4714016,"sourceId":8004432,"sourceType":"datasetVersion"},{"datasetId":4738233,"sourceId":8037319,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
